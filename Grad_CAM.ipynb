{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3dd000-e8ed-4580-ae74-af2b3991cdd7",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb143ae-d816-4a13-bf91-d2b9ffe6ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "import cv2\n",
    "from skimage import io, transform, segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c257a3-e932-4209-9f24-bb17aded7838",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34886e09-e8e9-4908-985a-5cb635aa7d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = io.imread('images/input/Maula.jpg')\n",
    "target_image_size = (299, 299)\n",
    "image = transform.resize(image, target_image_size)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f075860-4872-44f9-ab87-1f35911970e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea1305c-e440-4869-b491-5a31ac482834",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e728cf3f-2b99-4210-bef0-7531a9cd097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResNet50()\n",
    "model = InceptionV3() #Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e177da72-35ba-4778-8c8b-25a9b87828ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "# Inception preprocessing\n",
    "image = (image - 0.5)*2\n",
    "preds = model.predict(image[np.newaxis, ...])\n",
    "print(decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbd0d5f-f532-4145-aaca-2da3f8c67a1d",
   "metadata": {},
   "source": [
    "## Grad-CAM\n",
    "As a summary:\n",
    "- Step 1: The model is broken into to parts. The first part goes from the inputs to the the last convolutional layer (last_conv_layer_model). The second part goes from the last convolutional layer to the prediction (classifier_model).\n",
    "- Step 2: The image goes to the first part and then it starts being watched.\n",
    "- Step 3: After that, $\\alpha_k$ is computed for all the filters in the last conv layer.\n",
    "- Step 4: Finally, the activation map is obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37301179-e3dd-407d-a8c3-767d4c89b7ad",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2115b44e-846b-48e6-8a01-48d6b3d43095",
   "metadata": {},
   "source": [
    "We get the output of the last convolution layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31397543-759d-4b81-8457-8f46747b8373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "last_conv_layer_name = 'mixed10'\n",
    "last_conv_layer = model.get_layer(last_conv_layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2557da-8b94-40a8-a0dc-a2833bf5972c",
   "metadata": {},
   "source": [
    "We create a model that goes up to only that layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7f5185-dbf0-4bb2-86b5-5a79011d32dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_conv_layer_model = tf.keras.Model(model.inputs, last_conv_layer.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3fd18-2cc3-434c-942f-58d1011f6b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_layers = []\n",
    "last_conv_layer_found = False\n",
    "for layer in model.layers:\n",
    "    current_layer_name = layer.name\n",
    "    if current_layer_name == last_conv_layer_name:\n",
    "        last_conv_layer_found = True\n",
    "    if last_conv_layer_found and current_layer_name != last_conv_layer_name:\n",
    "        list_layers.append(current_layer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b27507e-6897-4f48-9ecd-9112dbee0fa4",
   "metadata": {},
   "source": [
    "We create a model which takes the output of the model above and uses the remaining layers to get the final predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae2771f-62f3-4304-83a2-569f99452b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_input = tf.keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "x = classifier_input\n",
    "for idx, layer_name in enumerate(list_layers): # These are the remaining layers in the ResNet50 model\n",
    "    x = model.get_layer(layer_name)(x)\n",
    "classifier_model = tf.keras.Model(classifier_input, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be3baca-a8a4-4854-8576-0796333e0dab",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e46454e-2d6e-4045-a1c4-bc5d3e1cb06c",
   "metadata": {},
   "source": [
    "- We get the output from the model up till the last convolution layer.\n",
    "- We ask tf to watch this tensor output, as we want to calculate the gradients of the predictions of our target class wrt to the output of this model (last convolution layer model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11d7e34-e93f-4aee-9b20-4d1f50010b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    inputs = image[np.newaxis, ...] #adding axis (batch)\n",
    "    last_conv_layer_output = last_conv_layer_model(inputs) #from beginning of RestNet to the last conv layer \n",
    "    tape.watch(last_conv_layer_output) # Start watching this part\n",
    "    preds = classifier_model(last_conv_layer_output) # Make a prediction\n",
    "    top_pred_index = tf.argmax(preds[0]) #Get the class of the highest probability\n",
    "    top_class_channel = preds[:, top_pred_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e7d00-17af-471f-aebe-1314787fe91e",
   "metadata": {},
   "source": [
    "We compute the gradient with respect to the last conv layer. Grads contains the following information:\n",
    "<h3 align=\"center\">$\\frac{\\partial y}{\\partial A_{ij}^k}$</h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8ea43e-9635-4edd-a3ad-1443f8bb5e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = tape.gradient(top_class_channel, last_conv_layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ad94ca-dfd6-4c1e-a6a4-5c0c7732d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grads.shape)\n",
    "print(last_conv_layer.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b64f5-11b7-42be-893a-6e3a57e38a8e",
   "metadata": {},
   "source": [
    "We compute $\\alpha_k = \\frac{1}{Z} \\sum_i \\sum_j \\frac{\\partial y}{\\partial A_{ij}^k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d620b60-08f6-4d57-b498-8cd275cb5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43615143-f203-4b93-a777-f5bcf22191b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pooled_grads.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0039e04-e2e3-446e-a244-b83752a26127",
   "metadata": {},
   "source": [
    "The next step is to compute $S = \\sum \\alpha_k A^k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16df31a1-9c88-467f-959f-9a49a4e963d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = last_conv_layer_output.numpy()[0]\n",
    "pooled_grads = pooled_grads.numpy()\n",
    "for i in range(pooled_grads.shape[-1]):\n",
    "    output[:, :, i] *= pooled_grads[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4804e-f924-4e08-b5b1-09375ad822bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam = np.sum(output, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6243ff-8079-46ac-bc43-3bbdb7b365d5",
   "metadata": {},
   "source": [
    "Finally, we apply $ReLU$ function to S: $L_{grad-CAM} = ReLU(s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca8d2bb-b674-4e41-b256-c658927b2b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradcam = np.clip(gradcam, 0, np.max(gradcam))\n",
    "gradcam = cv2.resize(gradcam, target_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e329b6c-93d3-42cf-b8bd-5dc167e34286",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)\n",
    "plt.imshow(gradcam, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df30249-e897-4982-9649-d5d141569675",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "DPI = fig.get_dpi()\n",
    "fig.set_size_inches(299.0/float(DPI),299.0/float(DPI))\n",
    "plt.imshow(image)\n",
    "plt.imshow(gradcam, alpha=0.5)\n",
    "plt.axis('off')\n",
    "fig.savefig('images/output/maula_gradcam.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
